{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HRL Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool Release Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRANetwork(nn.Module):\n",
    "    def __init__(self, input_dim=5, embedding_dim=128, hidden_dims=[256, 128], output_dim=2):\n",
    "        super(PRANetwork, self).__init__()\n",
    "        self.feature_extractor = nn.Linear(input_dim, embedding_dim)\n",
    "        layers = []\n",
    "        for i in range(len(hidden_dims)):\n",
    "            in_dim = embedding_dim if i == 0 else hidden_dims[i-1]\n",
    "            out_dim = hidden_dims[i]\n",
    "            layers.append(nn.Linear(in_dim, out_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.ff_network = nn.Sequential(*layers)\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.ff_network(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = F.softmax(x, dim=-1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Route Planning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim, num_heads, num_layers, order_dim=7, crowdsource_dim=5, inhouse_dim=3):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.order_embedding = nn.Linear(order_dim, dim)                # order_dim = 7\n",
    "        self.crowdsource_embedding = nn.Linear(crowdsource_dim, dim)    # crowdsource_dim = 5\n",
    "        self.inhouse_embedding = nn.Linear(inhouse_dim, dim)            # inhouse_dim = 3\n",
    "        self.layers = nn.ModuleList([nn.MultiheadAttention(dim, num_heads, batch_first=True) for _ in range(num_layers)])\n",
    "        self.norm_layers = nn.ModuleList([nn.BatchNorm1d(dim) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x_o, x_c, x_i):\n",
    "        h_o = self.order_embedding(x_o)\n",
    "        h_c = self.crowdsource_embedding(x_c)\n",
    "        h_i = self.inhouse_embedding(x_i)\n",
    "        \n",
    "        x = torch.cat((h_o, h_c, h_i), dim=0)\n",
    "        \n",
    "        for multi_head_attn, norm in zip(self.layers, self.norm_layers):\n",
    "            attn_output, _ = multi_head_attn(x, x, x)\n",
    "            x = x + attn_output\n",
    "            x = norm(x)\n",
    "            x = x + F.relu(x)\n",
    "            x = norm(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dim, output_dim, total_nodes, S, num_heads, is_cdrpa=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.multi_head_attn = nn.MultiheadAttention(dim, num_heads, batch_first=True)\n",
    "        self.cdrpa_embedding = nn.Linear(dim*2+1+1, dim)\n",
    "        self.cvrpa_embedding = nn.Linear(dim*2+1, dim)\n",
    "        self.is_cdrpa = is_cdrpa\n",
    "        self.W_Qs = nn.Linear(dim, dim)\n",
    "        self.W_Ks = nn.Linear(dim, dim)\n",
    "        self.output_layer = nn.Linear(total_nodes, output_dim)\n",
    "        self.S = S\n",
    "\n",
    "    def forward(self, context, H, mask):\n",
    "        if self.is_cdrpa:\n",
    "            context = self.cdrpa_embedding(context)\n",
    "        else: \n",
    "            context = self.cvrpa_embedding(context)\n",
    "            \n",
    "        H_c_t, _ = self.multi_head_attn(context, H, H)\n",
    "        Qs = self.W_Qs(H_c_t)\n",
    "        Ks = self.W_Ks(H)\n",
    "\n",
    "        u = self.S * torch.tanh((Qs @ Ks.transpose(0, 1)) / torch.sqrt(torch.tensor(Qs.size(-1), dtype=torch.float32)))\n",
    "        u = u.masked_fill(mask, float('-inf'))\n",
    "        \n",
    "        output = self.output_layer(u)\n",
    "        \n",
    "        return F.softmax(output, dim=1)\n",
    "    \n",
    "class RoutePolicyNetwork(nn.Module):\n",
    "    def __init__(self, dim, S, num_heads, num_layers):\n",
    "        super(RoutePolicyNetwork, self).__init__()\n",
    "        self.encoder = Encoder(dim, num_heads, num_layers)\n",
    "        \n",
    "    def forward(self, P_o, P_c, P_i):\n",
    "        P_c = sorted(P_c, key=lambda x: x['l_c'])           # Sorting crowdsource with latest depature time l_c\n",
    "        \n",
    "        x_o = torch.tensor([[*o['v_o'], *o['d_o'], o['e_o'], o['l_o'], o['w_o']] for o in P_o], dtype=torch.float32)\n",
    "        x_c = torch.tensor([[*c['u_c'], c['a_c'], c['l_c'], c['q_c']] for c in P_c], dtype=torch.float32)\n",
    "        x_i = torch.tensor([[*i['u_i'], i['q_i']] for i in P_i], dtype=torch.float32)\n",
    "        \n",
    "        H_N = self.encoder(x_o, x_c, x_i)                   # Embedding graph -> forward pass\n",
    "        \n",
    "        h_o = H_N[:x_o.shape[0], :].clone()\n",
    "        h_c = H_N[x_o.shape[0]:x_o.shape[0]+x_c.shape[0], :].clone()\n",
    "        h_i = H_N[x_o.shape[0]+x_c.shape[0]:, :].clone()\n",
    "        \n",
    "        assert h_o.shape[0] == x_o.shape[0], 'Invalid shape'\n",
    "        assert h_c.shape[0] == x_c.shape[0], 'Invalid shape'\n",
    "        assert h_i.shape[0] == x_i.shape[0], 'Invalid shape'\n",
    "        \n",
    "        h_N_mean = torch.mean(H_N, dim=0)     # Global graph embedding\n",
    "        \n",
    "        # print(H_N.shape)\n",
    "        # print(h_N_mean.shape)\n",
    "        # print(f\"Total Orders: {x_o.size(0)}\")\n",
    "        # print(f\"Total Crowdsources: {x_c.size(0)}\")\n",
    "        # print(f\"Total Inhouses: {x_i.size(0)}\")\n",
    "        \n",
    "        # output_dim must be the number of the order nodes\n",
    "        decoder_cdrpa = Decoder(dim=128, output_dim=x_o.size(0), S=1, total_nodes=H_N.size(0), num_heads=8, is_cdrpa=True)\n",
    "        decoder_cvrpa = Decoder(dim=128, output_dim=x_o.size(0), S=1, total_nodes=H_N.size(0), num_heads=8)\n",
    "\n",
    "        S_CDPRA_t = copy.deepcopy(P_o)                  # State S_CDPRA_t = P_o -> node of orders\n",
    "        # print(f\"P_o nodes: {S_CDPRA_t}\")\n",
    "        \n",
    "        mask = torch.zeros(H_N.size(0)).bool()          # Mask for the nodes\n",
    "        visited_idx_node_Po = []                        # Visited index of node in P_o\n",
    "        routes_policy_c = []                            # Routes policy for c\n",
    "        log_probs = []                                  # Log probabilities of the selected nodes\n",
    "        for idx_c in range(x_c.size(0)):                # CDRPA\n",
    "            if len(visited_idx_node_Po) >= len(P_o): \n",
    "                break\n",
    "            \n",
    "            t = 1\n",
    "            q = 0\n",
    "            t_travel = 0                                # Total time travel\n",
    "            h_uc = h_c[idx_c]                           # t = 1, the driver’s location information is the destination’s embedded feature h_uc\n",
    "            c = P_c[idx_c]                              # Crowdsource's information\n",
    "            Q = c['q_c']                                # Limitation capacity of crowdsource\n",
    "            L = c['l_c'] - c['a_c']                     # Limitation total time travel (driver's point -> pick-up -> next pick-up)\n",
    "            H_c_t_prev = None                           # Previous embedding previous visited node \n",
    "            v_o_prev = []                               # Previous v_o node\n",
    "            route = []\n",
    "            visited_idx_node_c = []                     # Visited node index for c\n",
    "            q_res = 0\n",
    "            t_travel_res = 0\n",
    "            while q < Q and t_travel < L:\n",
    "                q_r = torch.tensor(Q - q, dtype=torch.float32).unsqueeze(0)\n",
    "                t_travel_r = torch.tensor(L - t_travel, dtype=torch.float32).unsqueeze(0)\n",
    "                H_c_t = torch.cat((h_N_mean, h_uc, q_r, t_travel_r), dim=-1) if t == 1 else torch.cat((h_N_mean, H_c_t_prev, q_r, t_travel_r), dim=-1)\n",
    "                \n",
    "                probs_node = decoder_cdrpa(H_c_t.unsqueeze(0), H_N, mask)   # Probability distribution over node of Orders\n",
    "                \n",
    "                node = torch.multinomial(probs_node, 1)                     # Order node selection using sampling method\n",
    "                p_node = probs_node.squeeze(0)[node.item()]\n",
    "                log_prob = torch.log(p_node)                                # Log probability of the selected node\n",
    "                \n",
    "                o = P_o[node.item()]                                        # Next visited Order node\n",
    "                \n",
    "                if (q + o['w_o']) > Q:                                \n",
    "                    q_res = q                                               # Over-capacity\n",
    "                            \n",
    "                q += o['w_o']                                               # Consider capacity\n",
    "                \n",
    "                if t == 1:\n",
    "                    t_travel += self.t_uo(c['u_c'], o['v_o']) + self.t_uo(o['v_o'], o['d_o'])\n",
    "                    t_travel_res += t_travel\n",
    "                elif (t_travel + self.t_uo(v_o_prev, o['v_o'])) > L:\n",
    "                    t_travel_res = t_travel                                                     # Over-time travel\n",
    "                    t_travel += self.t_uo(v_o_prev, o['v_o'])\n",
    "                else:\n",
    "                    t_travel += self.t_uo(v_o_prev, o['v_o']) + self.t_uo(o['v_o'], o['d_o'])   # Time travel from prev v_o to next v_o, v_o to d_o\n",
    "                \n",
    "                route += [o] if q < Q and t_travel < L else []\n",
    "                visited_idx_node_c += [node.item()] if q < Q and t_travel < L else []\n",
    "                log_probs += [log_prob.item()] if q < Q and t_travel < L else []\n",
    "                \n",
    "                if node.item() not in visited_idx_node_Po and q < Q and t_travel < L:                  \n",
    "                    visited_idx_node_Po.append(node.item())                                     # Keep track visited node\n",
    "                \n",
    "                v_o_prev = o['d_o']\n",
    "                H_c_t_prev = h_o[node.item()]                                                   # Embedded feature of the driver’s previous visited node\n",
    "                    \n",
    "                t += 1\n",
    "            \n",
    "            # print(\"--------------------------------------------\")\n",
    "            # print(f\"Driver {c}\")\n",
    "            # print(f\"Total capacity: {q_res}\")\n",
    "            # print(f\"Total travel time: {t_travel_res}\")\n",
    "            # print(f\"Route: {route}\")\n",
    "            # print(f\"Visited idx node c: {visited_idx_node_c}\")\n",
    "            # print(f\"Visited P_o: {visited_idx_node_Po}\")\n",
    "            # print(f\"Visited len(P_o): {len(visited_idx_node_Po)}\")\n",
    "            routes_policy_c.append({\n",
    "                \"crowdsource\": c,\n",
    "                \"total_capacity\": q_res,\n",
    "                \"total_travel_time\": t_travel_res,\n",
    "                \"route\": route,\n",
    "                \"visited_idx_node\": visited_idx_node_c,\n",
    "            })\n",
    "        \n",
    "        routes_policy_i = []                    # Routes policy for i\n",
    "        for idx_i in range(x_i.size(0)):        # CVRPA\n",
    "            if len(visited_idx_node_Po) >= len(P_o): \n",
    "                break\n",
    "            \n",
    "            t = 1\n",
    "            q = 0\n",
    "            h_ui = h_i[idx_i]                   # t = 1, the driver’s location information is the destination’s embedded feature h_uc\n",
    "            i = P_i[idx_i]                      # Crowdsource's information\n",
    "            Q = i['q_i']                        # Limitation capacity of inhouse delivery\n",
    "            H_k_t_prev = None                   # Previous embedding previous visited node \n",
    "            route = []\n",
    "            visited_idx_node_i = []             # Visited node index for c\n",
    "            q_res = 0\n",
    "            while q < Q:\n",
    "                q_r = torch.tensor(Q - q, dtype=torch.float32).unsqueeze(0)\n",
    "                H_k_t = torch.cat((h_N_mean, h_ui, q_r), dim=-1) if t == 1 else torch.cat((h_N_mean, H_k_t_prev, q_r), dim=-1)\n",
    "                \n",
    "                probs_node = decoder_cvrpa(H_k_t.unsqueeze(0), H_N, mask)       # Probability distribution over node of orders\n",
    "                \n",
    "                node = torch.multinomial(probs_node, 1)                         # Order node selection using sampling method\n",
    "                p_node = probs_node.squeeze(0)[node.item()]\n",
    "                log_prob = torch.log(p_node)                                    # Log probability of the selected node\n",
    "                \n",
    "                o = P_o[node.item()]                                            # Next visited Order node\n",
    "                if (q + o['w_o']) > Q:                                \n",
    "                    q_res = q                                                   # Over-capacity\n",
    "                            \n",
    "                q += o['w_o']                                                   # Consider capacity\n",
    "                \n",
    "                route += [o] if q < Q else []\n",
    "                visited_idx_node_i += [node.item()] if q < Q else []\n",
    "                log_probs += [log_prob.item()] if q < Q else []\n",
    "                \n",
    "                if node.item() not in visited_idx_node_Po and q < Q:                      # Keep track visited node\n",
    "                    visited_idx_node_Po.append(node.item())\n",
    "                    \n",
    "                H_k_t_prev = h_o[node.item()]                                   # Embedded feature of the driver’s previous visited node\n",
    "                    \n",
    "                t += 1\n",
    "            \n",
    "            # print(\"--------------------------------------------\")\n",
    "            # print(f\"In-house delivery {i}\")\n",
    "            # print(f\"Total capacity: {q_res}\")\n",
    "            # print(f\"Route: {route}\")\n",
    "            # print(f\"Visited idx node i: {visited_idx_node_i}\")\n",
    "            # print(f\"Visited P_o: {visited_idx_node_Po}\")\n",
    "            # print(f\"Visited len(P_o): {len(visited_idx_node_Po)}\")\n",
    "            \n",
    "            routes_policy_i.append({\n",
    "                \"inhouse\": i,\n",
    "                \"total_capacity\": q_res,\n",
    "                \"route\": route,\n",
    "                \"visited_idx_node\": visited_idx_node_i,\n",
    "            })\n",
    "            \n",
    "        return routes_policy_c, routes_policy_i, log_probs\n",
    "    \n",
    "    def t_uo(self, u_c, v_o):\n",
    "        speed = 30\n",
    "        return np.around(np.sqrt((u_c[0] - v_o[0])**2 + (u_c[1] - v_o[1])**2) / speed, 2)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 2], [0, 1], [0, 1], [0, 1], [0, 1]]\n",
      "[[8, 7], [6, 5], [10, 2], [7, 7], [4, 7]]\n"
     ]
    }
   ],
   "source": [
    "grid_size = 3\n",
    "grid_spacing = 0.25\n",
    "num_grid_points = int(grid_size / grid_spacing)\n",
    "random.seed(0)\n",
    "grid_points = [[x, y] for x in range(num_grid_points) for y in range(num_grid_points)]\n",
    "\n",
    "def generate_coordinates(num, initial=False):\n",
    "    if initial:\n",
    "        num_zero_one = int(num * 0.85)\n",
    "        num_other = num - num_zero_one\n",
    "\n",
    "        depot_coords = [[0, 1]] * num_zero_one\n",
    "\n",
    "        other_coords = random.sample(grid_points, num_other)\n",
    "\n",
    "        sample = depot_coords + other_coords\n",
    "        random.shuffle(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    return random.sample(grid_points, num)\n",
    "\n",
    "print(generate_coordinates(5, initial=True))\n",
    "print(generate_coordinates(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random orders pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'e_o': 111.32, 'l_o': 110.59, 'v_o': [0, 1], 'd_o': [1, 6], 'w_o': 5.23},\n",
       " {'e_o': 127.3, 'l_o': 118.58, 'v_o': [0, 1], 'd_o': [7, 0], 'w_o': 6.68},\n",
       " {'e_o': 114.76, 'l_o': 112.31, 'v_o': [0, 1], 'd_o': [10, 0], 'w_o': 5.48},\n",
       " {'e_o': 127.26, 'l_o': 118.56, 'v_o': [0, 1], 'd_o': [11, 11], 'w_o': 9.15},\n",
       " {'e_o': 112.14, 'l_o': 111.0, 'v_o': [0, 1], 'd_o': [2, 1], 'w_o': 6.4},\n",
       " {'e_o': 122.84, 'l_o': 116.35, 'v_o': [10, 9], 'd_o': [7, 6], 'w_o': 5.68},\n",
       " {'e_o': 118.42, 'l_o': 114.14, 'v_o': [2, 11], 'd_o': [9, 3], 'w_o': 1.72},\n",
       " {'e_o': 115.18, 'l_o': 112.52, 'v_o': [0, 1], 'd_o': [6, 8], 'w_o': 1.57},\n",
       " {'e_o': 113.68, 'l_o': 111.77, 'v_o': [0, 1], 'd_o': [4, 4], 'w_o': 7.94},\n",
       " {'e_o': 110.1, 'l_o': 109.98, 'v_o': [0, 1], 'd_o': [11, 9], 'w_o': 7.01}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_orders_pool(num_orders, time_step, len_time_step=10, initial=False):\n",
    "    \"\"\"\n",
    "    time_step: 0, 1, 2,..., 54\n",
    "    len_time_step: length of a period = 10\n",
    "    e_o: early delivery time\n",
    "    l_o: late delivery time\n",
    "    v_o: co-ordinates pick up order\n",
    "    d_o: co-ordinates delivery order\n",
    "    a_o: order arrived time\n",
    "    p_o: pick up time\n",
    "    w_o: weight order\n",
    "    tw_o: time window between pick up and late delivery time\n",
    "    \"\"\"\n",
    "    a_o = np.around(\n",
    "        np.around(np.random.uniform(0, len_time_step, num_orders), 2)\n",
    "        + time_step * len_time_step, 2\n",
    "    )\n",
    "    p_o = np.around(a_o + np.around(np.random.uniform(0, 45), 2), 2)\n",
    "    tw_o = np.around(np.random.uniform(60, 120), 2)\n",
    "    e_o = np.around(a_o + p_o + tw_o, 2)\n",
    "    l_o = np.around(p_o + tw_o, 2)\n",
    "    w_o = np.around(np.random.uniform(0.5, 10, num_orders), 2)\n",
    "    v_o = generate_coordinates(num_orders, initial=initial)\n",
    "    d_o = generate_coordinates(num_orders)\n",
    "\n",
    "    return [{\"e_o\": i, \"l_o\": j, \"v_o\": k, \"d_o\": n, \"w_o\": m} for i, j, k, m, n in zip(e_o, l_o, v_o, w_o, d_o)]\n",
    "\n",
    "\n",
    "pool_orders = generate_random_orders_pool(10, 0, 10, initial=True)\n",
    "pool_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_o = torch.tensor([[*o['v_o'], o['e_o'], o['l_o'], o['w_o']] for o in pool_orders], dtype=torch.long)\n",
    "x_o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random crowdsources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a_c': 6.14, 'l_c': 159.84, 'q_c': 19.52, 'u_c': [10, 2]},\n",
       " {'a_c': 10.0, 'l_c': 163.7, 'q_c': 19.78, 'u_c': [9, 5]},\n",
       " {'a_c': 5.94, 'l_c': 159.64, 'q_c': 13.2, 'u_c': [11, 1]},\n",
       " {'a_c': 5.11, 'l_c': 158.81, 'q_c': 8.54, 'u_c': [5, 6]},\n",
       " {'a_c': 2.27, 'l_c': 155.97, 'q_c': 11.02, 'u_c': [1, 3]},\n",
       " {'a_c': 4.0, 'l_c': 157.7, 'q_c': 9.36, 'u_c': [11, 8]},\n",
       " {'a_c': 5.73, 'l_c': 159.43, 'q_c': 11.92, 'u_c': [0, 3]},\n",
       " {'a_c': 5.92, 'l_c': 159.62, 'q_c': 5.29, 'u_c': [1, 11]},\n",
       " {'a_c': 1.74, 'l_c': 155.44, 'q_c': 5.16, 'u_c': [8, 6]},\n",
       " {'a_c': 4.16, 'l_c': 157.86, 'q_c': 12.9, 'u_c': [0, 0]}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_crowdsources_pool(\n",
    "    num_crowdsources, time_step, len_time_step=10, initial=False\n",
    "):\n",
    "    \"\"\"\n",
    "    time_step: 0, 1, 2,..., 54\n",
    "    len_time_step: length of a period = 10\n",
    "    a_c: arrive time\n",
    "    l_c: leave time\n",
    "    q_c: carrying capacity\n",
    "    u_c: co-ordinates crowdsource\n",
    "    \"\"\"\n",
    "    a_c = np.around(\n",
    "        np.around(np.random.uniform(0, len_time_step, num_crowdsources), 2)\n",
    "        + time_step * len_time_step, 2\n",
    "    )\n",
    "    l_c = np.around(a_c + np.around(np.random.uniform(120, 180), 2), 2)\n",
    "    q_c = np.around(np.random.uniform(5, 20, num_crowdsources), 2)\n",
    "    u_c = generate_coordinates(num_crowdsources)\n",
    "\n",
    "    return [{\"a_c\": i, \"l_c\": j, \"q_c\": k, \"u_c\": m} for i, j, k, m in zip(a_c, l_c, q_c, u_c)]\n",
    "\n",
    "\n",
    "c = generate_random_crowdsources_pool(10, 0, 10, initial=True)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a_c': 1.74, 'l_c': 155.44, 'q_c': 5.16, 'u_c': [8, 6]},\n",
       " {'a_c': 2.27, 'l_c': 155.97, 'q_c': 11.02, 'u_c': [1, 3]},\n",
       " {'a_c': 4.0, 'l_c': 157.7, 'q_c': 9.36, 'u_c': [11, 8]},\n",
       " {'a_c': 4.16, 'l_c': 157.86, 'q_c': 12.9, 'u_c': [0, 0]},\n",
       " {'a_c': 5.11, 'l_c': 158.81, 'q_c': 8.54, 'u_c': [5, 6]},\n",
       " {'a_c': 5.73, 'l_c': 159.43, 'q_c': 11.92, 'u_c': [0, 3]},\n",
       " {'a_c': 5.92, 'l_c': 159.62, 'q_c': 5.29, 'u_c': [1, 11]},\n",
       " {'a_c': 5.94, 'l_c': 159.64, 'q_c': 13.2, 'u_c': [11, 1]},\n",
       " {'a_c': 6.14, 'l_c': 159.84, 'q_c': 19.52, 'u_c': [10, 2]},\n",
       " {'a_c': 10.0, 'l_c': 163.7, 'q_c': 19.78, 'u_c': [9, 5]}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data = sorted(c, key=lambda x: x['l_c'])\n",
    "sorted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random in-house delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'q_i': 1000, 'u_i': [0, 1]},\n",
       " {'q_i': 1000, 'u_i': [0, 1]},\n",
       " {'q_i': 1000, 'u_i': [0, 1]},\n",
       " {'q_i': 1000, 'u_i': [0, 1]},\n",
       " {'q_i': 1000, 'u_i': [0, 1]},\n",
       " {'q_i': 1000, 'u_i': [0, 1]},\n",
       " {'q_i': 1000, 'u_i': [0, 1]},\n",
       " {'q_i': 1000, 'u_i': [0, 1]},\n",
       " {'q_i': 1000, 'u_i': [0, 1]},\n",
       " {'q_i': 1000, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]},\n",
       " {'q_i': 25, 'u_i': [0, 1]}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_inhouse_pool(\n",
    "    num_trucks, num_motorbikes\n",
    "):\n",
    "    return [{\"q_i\": 1000, \"u_i\": [0,1]}]*num_trucks + [{\"q_i\": 25, \"u_i\": [0,1]}]*num_motorbikes\n",
    "\n",
    "\n",
    "generate_random_inhouse_pool(10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate travel time between nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = 30\n",
    "\n",
    "def t_oc(u_c, v_o):\n",
    "    return np.around(np.sqrt((u_c[0] - v_o[0])**2 + (u_c[1] - v_o[1])**2) / speed, 2)\n",
    "\n",
    "def t_ave(P_o_tau, P_c_tau):\n",
    "    return sum(t_oc(u_c=c['u_c'], v_o=o['v_o']) for o in P_o_tau for c in P_c_tau) / len(P_c_tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(routes_policy_c,\n",
    "                    routes_policy_i,\n",
    "                    t_oc,\n",
    "                    truck_cost,\n",
    "                    motobike_cost,\n",
    "                    late_penalty,\n",
    "                    duplicate_penalty,\n",
    "                    crowdsources_cost):\n",
    "   \n",
    "    waiting_cost_c = crowdsources_cost*1.5\n",
    "    # rewards_per_route_c = []  # List to store rewards for each route\n",
    "    rewards = []\n",
    "    for index, c in enumerate(routes_policy_c):\n",
    "        route = c['route']\n",
    "        if not route:\n",
    "            # rewards_per_route_c.append([])\n",
    "            rewards.extend([])\n",
    "            continue\n",
    "\n",
    "        # route_rewards = []  # Rewards for the current route\n",
    "        T_pi_c = t_oc(c['crowdsource']['u_c'], route[0]['v_o'])  # Initial travel time\n",
    "        initial_waiting_cost = max(route[0]['e_o'] - T_pi_c, 0) * waiting_cost_c\n",
    "        T_pi_c += t_oc(route[0]['v_o'], route[0]['d_o'])\n",
    "        late_delivery_penalty = late_penalty if T_pi_c > route[0]['l_o'] else 0\n",
    "        duplicate_penalty = 0  # Check for duplicate visit\n",
    "        initial_reward = (crowdsources_cost * T_pi_c + initial_waiting_cost + late_delivery_penalty + duplicate_penalty)\n",
    "        # route_rewards.append(initial_reward)\n",
    "        rewards.append(initial_reward)\n",
    "        # return\n",
    "        for n in range(len(route) - 1):\n",
    "            # Travel from current delivery to next pickup\n",
    "            T_pi_c += t_oc(route[n]['d_o'], route[n+1]['v_o'])\n",
    "            duplicate_penalty = duplicate_penalty if c['visited_idx_node'][n+1] in c['visited_idx_node'] else 0\n",
    "            waiting_time_cost = max(route[n+1]['e_o'] - T_pi_c, 0) * waiting_cost_c\n",
    "            T_pi_c += t_oc(route[n+1]['v_o'], route[n+1]['d_o'])\n",
    "            late_delivery_penalty = late_penalty if T_pi_c > route[n+1]['l_o'] else 0\n",
    "\n",
    "            node_reward = (crowdsources_cost * T_pi_c + waiting_time_cost + late_delivery_penalty)\n",
    "            # route_rewards.append(node_reward)\n",
    "            rewards.append(node_reward)\n",
    "       \n",
    "    # Reward for route i\n",
    "    rewards_per_route_i = []  # List to store rewards for each route for in-house drivers\n",
    "\n",
    "    for index, i in enumerate(routes_policy_i):\n",
    "        route = i['route']\n",
    "        if not route:\n",
    "            # rewards_per_route_i.append([])\n",
    "            rewards_per_route_i.extend([])\n",
    "            continue\n",
    "\n",
    "        route_rewards = []  # Rewards for the current route\n",
    "        waiting_cost_i = 1.5*truck_cost if i['inhouse'] == 1000 else 1.5*motobike_cost\n",
    "        T_pi_i = t_oc(i['inhouse']['u_i'], route[0]['v_o'])\n",
    "        initial_waiting_cost = max(route[0]['e_o'] - T_pi_i, 0) * waiting_cost_i\n",
    "        T_pi_i += t_oc(route[0]['v_o'], route[0]['d_o'])\n",
    "        late_delivery_penalty = late_penalty if T_pi_i > route[0]['l_o'] else 0\n",
    "        duplicate_penalty =  0\n",
    "        inhouse_cost = 1\n",
    "        if i['inhouse'] == 1000:\n",
    "            inhouse_cost = truck_cost\n",
    "        else:\n",
    "            inhouse_cost = motobike_cost\n",
    "           \n",
    "        initial_reward = (inhouse_cost * T_pi_i + initial_waiting_cost + late_delivery_penalty + duplicate_penalty)\n",
    "        # route_rewards.append(initial_reward)\n",
    "        rewards_per_route_i.append(initial_reward)\n",
    "\n",
    "\n",
    "        for n in range(len(route) - 1):\n",
    "            T_pi_i += t_oc(route[n]['d_o'], route[n+1]['v_o'])\n",
    "            duplicate_penalty = duplicate_penalty if i['visited_idx_node'][n+1] in i['visited_idx_node'] else 0\n",
    "            waiting_time_cost = max(route[n+1]['e_o'] - T_pi_i, 0) * waiting_cost_i\n",
    "            T_pi_i += t_oc(route[n+1]['v_o'], route[n+1]['d_o'])\n",
    "            late_delivery_penalty = late_penalty if T_pi_i > route[n+1]['l_o'] else 0\n",
    "\n",
    "            node_reward = (inhouse_cost * T_pi_i + waiting_time_cost + late_delivery_penalty)\n",
    "            # route_rewards.append(node_reward)\n",
    "            rewards_per_route_i.append(node_reward)\n",
    "    print(\"TC_c\", sum(rewards))\n",
    "    print(\"TC_i\", sum(rewards_per_route_i))\n",
    "    print(\"TC\", sum(rewards)+sum(rewards_per_route_i))\n",
    "   \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward at each node selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rewards_at_each_node(routes_policy_c, \n",
    "                                   routes_policy_i, \n",
    "                                   t_oc, \n",
    "                                   truck_cost,\n",
    "                                   motobike_cost,\n",
    "                                   late_penalty, \n",
    "                                   duplicate_penalty, \n",
    "                                   crowdsources_cost):\n",
    "    \n",
    "    waiting_cost_c = crowdsources_cost*1.5\n",
    "    # rewards_per_route_c = []  # List to store rewards for each route\n",
    "    rewards = []\n",
    "    for index, c in enumerate(routes_policy_c):\n",
    "        route = c['route']\n",
    "        if not route:\n",
    "            # rewards_per_route_c.append([])\n",
    "            rewards.extend([])\n",
    "            continue\n",
    "\n",
    "        # route_rewards = []  # Rewards for the current route\n",
    "        T_pi_c = t_oc(c['crowdsource']['u_c'], route[0]['v_o'])  # Initial travel time\n",
    "        initial_waiting_cost = max(route[0]['e_o'] - T_pi_c, 0) * waiting_cost_c\n",
    "        T_pi_c += t_oc(route[0]['v_o'], route[0]['d_o'])\n",
    "        late_delivery_penalty = late_penalty if T_pi_c > route[0]['l_o'] else 0\n",
    "        duplicate_penalty = 0  # Check for duplicate visit\n",
    "        initial_reward = -(crowdsources_cost * T_pi_c + initial_waiting_cost + late_delivery_penalty + duplicate_penalty)\n",
    "        # route_rewards.append(initial_reward)\n",
    "        rewards.append(initial_reward)\n",
    "        # return\n",
    "        for n in range(len(route) - 1):\n",
    "            # Travel from current delivery to next pickup\n",
    "            T_pi_c += t_oc(route[n]['d_o'], route[n+1]['v_o'])\n",
    "            duplicate_penalty = duplicate_penalty if c['visited_idx_node'][n+1] in c['visited_idx_node'] else 0\n",
    "            waiting_time_cost = max(route[n+1]['e_o'] - T_pi_c, 0) * waiting_cost_c\n",
    "            T_pi_c += t_oc(route[n+1]['v_o'], route[n+1]['d_o'])\n",
    "            late_delivery_penalty = late_penalty if T_pi_c > route[n+1]['l_o'] else 0\n",
    "\n",
    "            node_reward = -(crowdsources_cost * T_pi_c + waiting_time_cost + late_delivery_penalty)\n",
    "            # route_rewards.append(node_reward)\n",
    "            rewards.append(node_reward)\n",
    "\n",
    "        # rewards_per_route_c.append(route_rewards)\n",
    "        \n",
    "    # Reward for route i\n",
    "    rewards_per_route_i = []  # List to store rewards for each route for in-house drivers\n",
    "\n",
    "    for index, i in enumerate(routes_policy_i):\n",
    "        route = i['route']\n",
    "        if not route:\n",
    "            # rewards_per_route_i.append([])\n",
    "            rewards.extend([])\n",
    "            continue\n",
    "\n",
    "        route_rewards = []  # Rewards for the current route\n",
    "        waiting_cost_i = 1.5*truck_cost if i['inhouse'] == 1000 else 1.5*motobike_cost\n",
    "        T_pi_i = t_oc(i['inhouse']['u_i'], route[0]['v_o'])\n",
    "        initial_waiting_cost = max(route[0]['e_o'] - T_pi_i, 0) * waiting_cost_i\n",
    "        T_pi_i += t_oc(route[0]['v_o'], route[0]['d_o'])\n",
    "        late_delivery_penalty = late_penalty if T_pi_i > route[0]['l_o'] else 0\n",
    "        duplicate_penalty =  0\n",
    "        inhouse_cost = 1\n",
    "        if i['inhouse'] == 1000:\n",
    "            inhouse_cost = truck_cost\n",
    "        else:\n",
    "            inhouse_cost = motobike_cost\n",
    "            \n",
    "        initial_reward = -(inhouse_cost * T_pi_i + initial_waiting_cost + late_delivery_penalty + duplicate_penalty)\n",
    "        # route_rewards.append(initial_reward)\n",
    "        rewards.append(initial_reward)\n",
    "\n",
    "        for n in range(len(route) - 1):\n",
    "            T_pi_i += t_oc(route[n]['d_o'], route[n+1]['v_o'])\n",
    "            duplicate_penalty = duplicate_penalty if i['visited_idx_node'][n+1] in i['visited_idx_node'] else 0\n",
    "            waiting_time_cost = max(route[n+1]['e_o'] - T_pi_i, 0) * waiting_cost_i\n",
    "            T_pi_i += t_oc(route[n+1]['v_o'], route[n+1]['d_o'])\n",
    "            late_delivery_penalty = late_penalty if T_pi_i > route[n+1]['l_o'] else 0\n",
    "\n",
    "            node_reward = -(inhouse_cost * T_pi_i + waiting_time_cost + late_delivery_penalty)\n",
    "            # route_rewards.append(node_reward)\n",
    "            rewards.append(node_reward)\n",
    "\n",
    "        # rewards_per_route_i.append(route_rewards)\n",
    "\n",
    "    # return rewards_per_route_c, rewards_per_route_i \n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(num_episodes, \n",
    "                  num_batches=1, \n",
    "                  planning_horizons=10, \n",
    "                  len_periods=10, \n",
    "                  num_trucks=10, \n",
    "                  num_motobikes=20,\n",
    "                  truck_cost=5,\n",
    "                  motobike_cost=3,\n",
    "                  crowdsources_cost=3,\n",
    "                  late_penalty=15,\n",
    "                  duplicate_penalty=10\n",
    "                  ):\n",
    "    \n",
    "    policy_network = RoutePolicyNetwork(dim=128, S=1, num_heads=8, num_layers=6)\n",
    "    baseline_network = RoutePolicyNetwork(dim=128, S=1, num_heads=8, num_layers=6)\n",
    "    baseline_network.load_state_dict(policy_network.state_dict())\n",
    "    \n",
    "    pra_network = PRANetwork()\n",
    "    \n",
    "    policy_optimizer = optim.Adam(policy_network.parameters(), lr=1e-3)\n",
    "    pra_optimizer = optim.Adam(pra_network.parameters(), lr=1e-3)\n",
    "    \n",
    "    total_rewards_per_epoch = []\n",
    "    total_losses_per_epoch = []\n",
    "    \n",
    "    for epoch in range(num_episodes):\n",
    "        for batch in range(num_batches):\n",
    "            n_io = np.round(np.random.uniform(90, 120)).astype(int) # Number of initial orders\n",
    "            n_ic = np.round(np.random.uniform(50, 60)).astype(int)  # Number of initial crowdsources\n",
    "            P_o = []                                                # Orders pool\n",
    "            P_c = []                                                # Crowdsources pool\n",
    "            T = len_periods                                         # 8:10\n",
    "            P_i = generate_random_inhouse_pool(num_trucks, num_motobikes)              # In-house delivery pool\n",
    "            \n",
    "            log_probs = []\n",
    "            rewards = []\n",
    "            for tau in range(planning_horizons):                        # Planning horizons -> #time steps which decision-making process occurs\n",
    "                N_o = np.round(np.random.uniform(30, 45)).astype(int)   # New placed orders\n",
    "                N_c = np.round(np.random.uniform(15, 25)).astype(int)   # New arrived crowdsources\n",
    "                \n",
    "                P_o_tau = []\n",
    "                P_c_tau = []\n",
    "                if tau == 0:\n",
    "                    P_o_tau = generate_random_orders_pool(n_io, 0, len_periods, initial=True) + generate_random_orders_pool(N_o, tau, len_periods)\n",
    "                    P_c_tau = generate_random_crowdsources_pool(n_ic, 0, len_periods, initial=True) + generate_random_crowdsources_pool(N_c, tau, len_periods)\n",
    "                \n",
    "                else:\n",
    "                    P_o_tau = P_o + generate_random_orders_pool(N_o, tau, len_periods)\n",
    "                    P_c_tau = P_c + generate_random_crowdsources_pool(N_c, tau, len_periods)\n",
    "                \n",
    "                # State S_PRA_tau\n",
    "                n_tau = len(P_o_tau)                                        # Number of current orders\n",
    "                m_tau = len(P_c_tau)                                        # Number of current crowdsources\n",
    "                l_star_o_tau = min(P_o_tau, key=lambda x: x['l_o'])['l_o']  # Late delivery time of the most urgent orders\n",
    "                l_star_c_tau = min(P_c_tau, key=lambda x: x['l_c'])['l_c']  # Last departure time of almost leaving crowdsource\n",
    "                t_ave_tau = t_ave(P_o_tau, P_c_tau)                         # Average travel time between locations of crowdsources and pick-up orders\n",
    "                S_PRA_tau = [n_tau, m_tau, l_star_o_tau, l_star_c_tau, t_ave_tau]\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    state_tensor = torch.tensor(S_PRA_tau, dtype=torch.float).unsqueeze(0)\n",
    "                    probabilities = pra_network(state_tensor)\n",
    "                    action = torch.multinomial(probabilities, 1) # the decision is selected using the sampling method\n",
    "                    \n",
    "                if action.item() == 1:\n",
    "                    routes_policy_c, routes_policy_i, log_probs_tau = policy_network(P_o_tau, P_c_tau, P_i)   # Lower-agent construct route policy\n",
    "                    \n",
    "                    route_rewards = calculate_rewards_at_each_node(routes_policy_c, routes_policy_i, t_oc, truck_cost, motobike_cost, late_penalty, duplicate_penalty, crowdsources_cost)\n",
    "                    \n",
    "                    assert len(route_rewards) == len(log_probs_tau), 'Invalid rewards, log_probs'\n",
    "                    \n",
    "                    baseline_network = baseline_network.eval()\n",
    "                    baseline_routes_policy_c, baseline_routes_policy_i, _ = baseline_network(P_o_tau, P_c_tau, P_i)\n",
    "                    baseline_route_rewards = calculate_rewards_at_each_node(baseline_routes_policy_c, baseline_routes_policy_i, t_oc, truck_cost, motobike_cost, late_penalty, duplicate_penalty, crowdsources_cost)\n",
    "                    \n",
    "                    log_probs.extend(log_probs_tau)\n",
    "                    rewards.extend(route_rewards)\n",
    "                    baseline_route_rewards.extend(baseline_route_rewards)\n",
    "                    P_o_tau = []\n",
    "                    P_c_tau = []\n",
    "                    print(f\"Epoch: {epoch}, Tau: {tau}\")\n",
    "                \n",
    "                P_o.extend(P_o_tau)\n",
    "                T += len_periods                                            # Next length period 8:20, crowdsource 8:15 -> out-dated\n",
    "                P_c_tau = [c for c in P_c_tau if c['l_c'] > T]              # Weed out expired crowd drivers\n",
    "                P_c.extend(P_c_tau)\n",
    "            \n",
    "            # Calculate Loss\n",
    "            policy_reward = torch.tensor(rewards)\n",
    "            baselime_rewards = torch.tensor(baseline_route_rewards)\n",
    "            gradient_reward = policy_reward - baselime_rewards\n",
    "            rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-9)   # Normalize rewards\n",
    "            \n",
    "            policy_loss = []\n",
    "            for log_prob, R in zip(log_probs, rewards):\n",
    "                policy_loss.append(-log_prob * R)                           # Negative log probability multiplied by return\n",
    "                \n",
    "            improve = (baselime_rewards - policy_reward).mean() >= 0\n",
    "            _,  p_value = stats.ttest_rel(baselime_rewards, policy_reward)\n",
    "            if improve and p_value <= 0.05:\n",
    "                baseline_network.load_state_dict(policy_network.state_dict())\n",
    "                self._bdl = self.baseline_dataloader()\n",
    "            \n",
    "            if len(policy_loss) > 0:\n",
    "                policy_loss = torch.sum(torch.stack(policy_loss))\n",
    "                policy_loss = policy_loss.detach().clone().requires_grad_(True)\n",
    "\n",
    "            policy_optimizer.zero_grad()\n",
    "            policy_loss.backward()\n",
    "            policy_optimizer.step()\n",
    "            \n",
    "            pra_optimizer.zero_grad()\n",
    "            policy_loss.backward()\n",
    "            pra_optimizer.step()\n",
    "            \n",
    "            total_reward = sum(rewards.numpy())\n",
    "            total_rewards_per_epoch.append(total_reward)\n",
    "            \n",
    "            total_loss = policy_loss.item()\n",
    "            total_losses_per_epoch.append(total_loss)\n",
    "            \n",
    "            print(f\"Epoch: {epoch}, Total Reward: {sum(rewards)}, Loss: {policy_loss}\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    plt.plot(range(num_episodes), total_rewards_per_epoch, label='Total Rewards', color='blue')\n",
    "    plt.plot(range(num_episodes), total_losses_per_epoch, label='Losses', color='red')\n",
    "    plt.legend()\n",
    "    plt.title('Total Rewards and Losses Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Value')\n",
    "\n",
    "    plt.show()\n",
    "    calculate_cost(routes_policy_c, routes_policy_i, t_oc, truck_cost, motobike_cost, late_penalty, duplicate_penalty, crowdsources_cost)\n",
    "    \n",
    "    # fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    # fig.add_trace(\n",
    "    #     go.Scatter(x=list(range(num_episodes)), y=total_rewards_per_epoch, name=\"Total Rewards\"),\n",
    "    #     secondary_y=False,)\n",
    "\n",
    "    # fig.add_trace(\n",
    "    #     go.Scatter(x=list(range(num_episodes)), y=total_losses_per_epoch, name=\"Losses\"),\n",
    "    #     secondary_y=True,)\n",
    "\n",
    "    # fig.update_layout(title_text=\"Total Rewards and Losses Over Epochs\")\n",
    "    # fig.update_xaxes(title_text=\"Epoch\")\n",
    "    # fig.update_yaxes(title_text=\"Rewards\", secondary_y=False)\n",
    "    # fig.update_yaxes(title_text=\"Losses\", secondary_y=True)\n",
    "    # fig.show()\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Total Reward: -3.782085755688058e-12, Loss: 1234.0491425552534\n",
      "Epoch: 1, Total Reward: 2.581268532253489e-12, Loss: 1135.4273130239694\n",
      "Epoch: 2, Total Reward: -1.0798029137504273e-12, Loss: 1399.8910293522913\n",
      "Epoch: 3, Total Reward: 5.289102489314246e-13, Loss: 1216.4433513467768\n",
      "Epoch: 4, Total Reward: 1.0906830993917538e-12, Loss: 1254.1903563051094\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TC_c 66115.39499999999\n",
      "TC_i 235836.22499999995\n",
      "TC 301951.61999999994\n"
     ]
    }
   ],
   "source": [
    "training_loop(5, 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
